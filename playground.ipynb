{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72db6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fe1ae77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8786431307515659,\n",
       " 0.02865595771819071,\n",
       " 0.012344635480324384,\n",
       " 0.010712580377896158,\n",
       " 0.007945304756589056,\n",
       " 0.008145043678833064,\n",
       " 0.010687641461152614,\n",
       " 0.013192261723785459,\n",
       " 0.016911443286873856,\n",
       " 0.020114605027894722,\n",
       " 0.02635363474356653,\n",
       " 0.030209825229025183,\n",
       " 0.032271321900338296,\n",
       " 0.03522470501741087,\n",
       " 0.03730167941275511,\n",
       " 0.0424363124975172,\n",
       " 0.0460241475119369,\n",
       " 0.04737130553497762,\n",
       " 0.051858460256311495,\n",
       " 0.04985118483729031,\n",
       " 0.053380099567878675,\n",
       " 0.05049064415166116,\n",
       " 0.05366042848140387,\n",
       " 0.04291894399760937]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "covs = torch.load(\"./calibs/opt-1.3b-0_4-alt_bi-2.pt\")\n",
    "bi_scores = copy.deepcopy(covs[\"bi_scores\"])\n",
    "del covs\n",
    "bi_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import compression_utils as CU\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importlib.reload(CU)\n",
    "smoothing = 0.01\n",
    "inc = 0.1\n",
    "sparsities = []\n",
    "while smoothing <= 2:\n",
    "    sparsity = CU.allocate_global_sparsity(\n",
    "        bi_scores, compression_ratio=0.4, smoothing=smoothing\n",
    "    )  # reversing the minus 1\n",
    "    sparsities.append(sparsity)\n",
    "    smoothing += inc\n",
    "\n",
    "# Create figure and axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create x-axis values (layer numbers)\n",
    "layers = np.arange(len(sparsities[0]))\n",
    "\n",
    "# Plot a line for each smoothing value\n",
    "for idx, sparsity in enumerate(sparsities):\n",
    "    smoothing_val = 0.01 + (idx * 0.1)  # Calculate the smoothing value\n",
    "    plt.plot(layers, sparsity, label=f\"Smoothing: {smoothing_val:.1f}\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Layer Number\")\n",
    "plt.ylabel(\"Sparsity\")\n",
    "plt.title(\"Sparsity Distribution Across Layers for Different Smoothing Values\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5121a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot for bi_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Convert bi_scores to numpy if it's a torch tensor\n",
    "if torch.is_tensor(bi_scores):\n",
    "    bi_scores_np = bi_scores.cpu().numpy()\n",
    "else:\n",
    "    bi_scores_np = np.array(bi_scores)\n",
    "\n",
    "# Create x-axis values (layer indices)\n",
    "layers = np.arange(len(bi_scores_np))\n",
    "\n",
    "# Create a bar plot of the scores\n",
    "plt.bar(layers, bi_scores_np, alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Layer Index\")\n",
    "plt.ylabel(\"Score Value\")\n",
    "plt.title(\"Bi-scores Distribution Across Layers\")\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print shape information\n",
    "print(f\"Bi-scores shape: {bi_scores_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc91cc",
   "metadata": {},
   "source": [
    "## Calibration testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984e7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbac/Documents/prgTHINGS/FSUJob/ModeGPT/RefactorMoDeGPT/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_utils import load_model, get_model_attrs\n",
    "from compression_utils import get_embedders, get_layer_block\n",
    "import eval\n",
    "import importlib\n",
    "\n",
    "importlib.reload(eval)\n",
    "\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785fdd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, config = load_model(\"facebook/opt-1.3b\")\n",
    "model.cuda()\n",
    "text_arr = eval.load_calibration_texts(4, model, tokenizer)\n",
    "\n",
    "inputs = tokenizer(\n",
    "    text_arr.tolist(), return_tensors=\"pt\", truncation=True, padding=True, max_length=2048\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af45f0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2048])\n"
     ]
    }
   ],
   "source": [
    "input_ids = inputs.input_ids.to(\"cuda\")\n",
    "print(input_ids.shape)\n",
    "\n",
    "n_layers, n_heads, d_model, head_dim, arch = get_model_attrs(model)\n",
    "\n",
    "cov_q_list = [\n",
    "    [torch.zeros(head_dim, head_dim, dtype=torch.float64, device=\"cuda\") for _ in range(n_heads)]\n",
    "    for _ in range(n_layers)\n",
    "]\n",
    "cov_k_list = [\n",
    "    [torch.zeros(head_dim, head_dim, dtype=torch.float64, device=\"cuda\") for _ in range(n_heads)]\n",
    "    for _ in range(n_layers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cccbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embed_tokens, embed_positions = get_embedders(model)\n",
    "    token_embeddings = embed_tokens(input_ids)\n",
    "    position_ids = torch.arange(0, 2048, dtype=torch.long, device=\"cuda\").unsqueeze(0)\n",
    "    position_embeddings = embed_positions(position_ids)\n",
    "    print(\n",
    "        f\"token_embeddings.shape = {token_embeddings.shape}, position_embeddings.shape = {position_embeddings.shape}\"\n",
    "    )\n",
    "    hidden_states = token_embeddings + position_embeddings\n",
    "    print(f\"hidden_states.shape = {hidden_states.shape}\")\n",
    "    layer = get_layer_block(model, 0)\n",
    "    print(f\"q_proj.shape {layer.self_attn.q_proj.weight.shape}\")\n",
    "    q_states = layer.self_attn.q_proj(hidden_states)\n",
    "    print(f\"q_states.shape = {q_states.shape}\")\n",
    "    # for layer in range(n_layers):\n",
    "    #     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927e65f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2048])\n",
      "head1_bias.reshape(1, -1).shape = torch.Size([1, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2049, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.zeros((2048, 2048))\n",
    "B = A.split(64, dim=0)\n",
    "head1 = B[0]\n",
    "print(head1.shape)\n",
    "\n",
    "head1_bias =  torch.zeros(64).reshape(1, -1)\n",
    "print(f\"head1_bias.reshape(1, -1).shape = {head1_bias.shape}\")\n",
    "\n",
    "some_tensor = torch.cat((head1.mT, head1_bias))\n",
    "some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa572a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
